{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organizational-standard",
   "metadata": {},
   "source": [
    "## We will first train a ColBERT sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "utility-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4122018096975150724\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11153683264\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6393585071727212234\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Machine details\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow import keras\n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monetary-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data\n",
    "training_sample_count = 1000 # 4000\n",
    "test_count = 1000\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-italian",
   "metadata": {},
   "source": [
    "## Read training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impressive-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"joke-gen/ColBERT humor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifth-stanley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  What kind of cat should you take into the  des...   True\n",
       "1  Remember when people used to have to be in sha...   True\n",
       "2  Pizza is always good. - everyone we'll see abo...   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/dataset.csv')\n",
    "\n",
    "df_train = pd.read_csv('Data/train.csv')\n",
    "display(df_train.head(3))\n",
    "df_train = df_train[:training_sample_count]\n",
    "\n",
    "df_test = pd.read_csv('Data/dev.csv')\n",
    "display(df_test.head(3))\n",
    "df_test = df_test[:test_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cathedral-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 1000 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 reasons the 2016 election feels so personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True\n",
       "3      5 reasons the 2016 election feels so personal  False\n",
       "4  Pasco police shot mexican migrant from behind,...  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black teen's response to violence in his commu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  What kind of cat should you take into the  des...\n",
       "1  Remember when people used to have to be in sha...\n",
       "2  Pizza is always good. - everyone we'll see abo...\n",
       "3  What's 6 inches long hard, bent, and in my pan...\n",
       "4  Black teen's response to violence in his commu..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df_y = df_test.copy()\n",
    "del df_test['humor']\n",
    "\n",
    "df_sub = test_df_y.copy()\n",
    "\n",
    "print(len(df),len(df_train),len(df_test))\n",
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "supposed-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input categories:\n",
      "\t ['text']\n",
      "\n",
      "output TARGET_COUNT:\n",
      "\t 1\n",
      "\n",
      "output categories:\n",
      "\t ['humor']\n"
     ]
    }
   ],
   "source": [
    "output_categories = list(df_train.columns[[1]])\n",
    "input_categories = list(df_train.columns[[0]])\n",
    "\n",
    "TARGET_COUNT = len(output_categories)\n",
    "\n",
    "print('\\ninput categories:\\n\\t', input_categories)\n",
    "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
    "print('\\noutput categories:\\n\\t', output_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-breeding",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "younger-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hawaiian-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southeast-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bright-aaron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006bf4b848d64fc4a0823e5ee3ff7bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7908ae51b74fecaf199a1ff252f1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "inputs      = compute_input_arrays(df_train, input_categories, tokenizer)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pediatric-framing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 1000 20\n",
      "Why do native americans hate it when it rains in april? because it brings mayflowers.\n",
      "['Why do native americans hate it when it rains in april?', 'because it brings mayflowers.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  101,  2339,  2079,  3128,  4841,  5223,  2009,  2043,  2009,\n",
       "        15811,  1999,  2258,  1029,   102,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int32),\n",
       " array([  101,  2138,  2009,  7545,  2089, 14156,  2015,  1012,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int32),\n",
       " array([101, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0], dtype=int32),\n",
       " array([  101,  2339,  2079,  3128,  4841,  5223,  2009,  2043,  2009,\n",
       "        15811,  1999,  2258,  1029,  2138,  2009,  7545,  2089, 14156,\n",
       "         2015,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(inputs), len(inputs[0]), len(inputs[0][0]))\n",
    "\n",
    "# check out input for 7th row\n",
    "xx = 7\n",
    "print(df_train.iloc[xx,0])\n",
    "print(sent_tokenize(df_train.iloc[xx,0]))\n",
    "inputs[0][xx], inputs[3][xx], inputs[6][xx], inputs[15][xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worth-recipient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-newfoundland",
   "metadata": {},
   "source": [
    "## Load untrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bridal-dayton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          multiple             109482240   input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "                                                                 input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "                                                                 input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "                                                                 input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "                                                                 input_31[0][0]                   \n",
      "                                                                 input_32[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "                                                                 input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 768)          0           bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 768)          0           bert[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 768)          0           bert[2][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 768)          0           bert[3][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 768)          0           bert[4][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 768)          0           bert[5][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           24608       global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 32)           24608       global_average_pooling1d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 32)           24608       global_average_pooling1d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 32)           24608       global_average_pooling1d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           24608       global_average_pooling1d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          196864      global_average_pooling1d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 32)           0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 32)           0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 32)           0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 32)           0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 256)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 8)            264         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            264         dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            264         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 8)            264         dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 8)            264         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 64)           16448       dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 104)          0           dense_16[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "                                                                 dense_22[0][0]                   \n",
      "                                                                 dense_24[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 512)          53760       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 512)          0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 256)          131328      dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1)            257         dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,005,257\n",
      "Trainable params: 110,005,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MAX_SENTENCE_LENGTH = 20\n",
    "import json\n",
    "with open(\"modelConf.json\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "model = keras.models.model_from_json(json.dumps(config))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-samoa",
   "metadata": {},
   "source": [
    "Since it's a regression with outcome between 0 and 1, it's reasonable to use binary_crossentropy optimizer and MAE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exterior-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"mae\",\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "homeless-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "32/32 [==============================] - 184s 2s/step - loss: 0.7233 - mae: 0.4968 - accuracy: 0.5148\n",
      "Epoch 2/70\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.7158 - mae: 0.5037 - accuracy: 0.4917\n",
      "Epoch 3/70\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.6974 - mae: 0.4989 - accuracy: 0.5148\n",
      "Epoch 4/70\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.6972 - mae: 0.4998 - accuracy: 0.5021\n",
      "Epoch 5/70\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.7056 - mae: 0.5029 - accuracy: 0.4891\n",
      "Epoch 6/70\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.6939 - mae: 0.4995 - accuracy: 0.5068\n",
      "Epoch 7/70\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6956 - mae: 0.5001 - accuracy: 0.4963\n",
      "Epoch 8/70\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6951 - mae: 0.5002 - accuracy: 0.5075\n",
      "Epoch 9/70\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.7004 - mae: 0.5019 - accuracy: 0.4913\n",
      "Epoch 10/70\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6956 - mae: 0.5005 - accuracy: 0.4878\n",
      "Epoch 11/70\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6931 - mae: 0.4998 - accuracy: 0.5012\n",
      "Epoch 12/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6931 - mae: 0.5000 - accuracy: 0.5016\n",
      "Epoch 13/70\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6946 - mae: 0.5006 - accuracy: 0.4768\n",
      "Epoch 14/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6929 - mae: 0.4998 - accuracy: 0.5193\n",
      "Epoch 15/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6934 - mae: 0.5001 - accuracy: 0.5048\n",
      "Epoch 16/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.4965\n",
      "Epoch 17/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6938 - mae: 0.5003 - accuracy: 0.4905\n",
      "Epoch 18/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6935 - mae: 0.5001 - accuracy: 0.4943\n",
      "Epoch 19/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6931 - mae: 0.5000 - accuracy: 0.5079\n",
      "Epoch 20/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5101\n",
      "Epoch 21/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6935 - mae: 0.5002 - accuracy: 0.4870\n",
      "Epoch 22/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5027\n",
      "Epoch 23/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6927 - mae: 0.4997 - accuracy: 0.5255\n",
      "Epoch 24/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6925 - mae: 0.4996 - accuracy: 0.5279\n",
      "Epoch 25/70\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5084\n",
      "Epoch 26/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6925 - mae: 0.4996 - accuracy: 0.5243\n",
      "Epoch 27/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6924 - mae: 0.4996 - accuracy: 0.5281\n",
      "Epoch 28/70\n",
      "32/32 [==============================] - 70s 2s/step - loss: 0.6931 - mae: 0.4999 - accuracy: 0.5127\n",
      "Epoch 29/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5095\n",
      "Epoch 30/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6922 - mae: 0.4995 - accuracy: 0.5299\n",
      "Epoch 31/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6931 - mae: 0.4999 - accuracy: 0.5057\n",
      "Epoch 32/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6931 - mae: 0.4999 - accuracy: 0.5092\n",
      "Epoch 33/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6935 - mae: 0.5001 - accuracy: 0.4977\n",
      "Epoch 34/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5013\n",
      "Epoch 35/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6934 - mae: 0.5000 - accuracy: 0.4981\n",
      "Epoch 36/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6928 - mae: 0.4997 - accuracy: 0.5147\n",
      "Epoch 37/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6929 - mae: 0.4998 - accuracy: 0.5135\n",
      "Epoch 38/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6939 - mae: 0.5003 - accuracy: 0.4913\n",
      "Epoch 39/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6933 - mae: 0.5000 - accuracy: 0.4997\n",
      "Epoch 40/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5019\n",
      "Epoch 41/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5094\n",
      "Epoch 42/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5121\n",
      "Epoch 43/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6926 - mae: 0.4997 - accuracy: 0.5287\n",
      "Epoch 44/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6934 - mae: 0.5001 - accuracy: 0.4969\n",
      "Epoch 45/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5095\n",
      "Epoch 46/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6936 - mae: 0.5002 - accuracy: 0.4882\n",
      "Epoch 47/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5113\n",
      "Epoch 48/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6933 - mae: 0.5000 - accuracy: 0.5018\n",
      "Epoch 49/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6927 - mae: 0.4997 - accuracy: 0.5265\n",
      "Epoch 50/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5017\n",
      "Epoch 51/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5012\n",
      "Epoch 52/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6931 - mae: 0.4999 - accuracy: 0.5063\n",
      "Epoch 53/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6933 - mae: 0.5000 - accuracy: 0.5002\n",
      "Epoch 54/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6929 - mae: 0.4998 - accuracy: 0.5134\n",
      "Epoch 55/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6928 - mae: 0.4998 - accuracy: 0.5185\n",
      "Epoch 56/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6937 - mae: 0.5002 - accuracy: 0.4861\n",
      "Epoch 57/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6927 - mae: 0.4997 - accuracy: 0.5221\n",
      "Epoch 58/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6928 - mae: 0.4998 - accuracy: 0.5194\n",
      "Epoch 59/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6936 - mae: 0.5002 - accuracy: 0.4870\n",
      "Epoch 60/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5114\n",
      "Epoch 61/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6931 - mae: 0.4999 - accuracy: 0.5083\n",
      "Epoch 62/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5010\n",
      "Epoch 63/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6930 - mae: 0.4999 - accuracy: 0.5105\n",
      "Epoch 64/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6932 - mae: 0.5000 - accuracy: 0.5028\n",
      "Epoch 65/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6927 - mae: 0.4997 - accuracy: 0.5186\n",
      "Epoch 66/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6924 - mae: 0.4996 - accuracy: 0.5244\n",
      "Epoch 67/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6927 - mae: 0.4997 - accuracy: 0.5196\n",
      "Epoch 68/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6928 - mae: 0.4998 - accuracy: 0.5154\n",
      "Epoch 69/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6926 - mae: 0.4997 - accuracy: 0.5205\n",
      "Epoch 70/70\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6933 - mae: 0.5000 - accuracy: 0.4996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4365517350>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs,outputs,epochs=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-cosmetic",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spanish-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "import sklearn\n",
    "def print_evaluation_metrics(y_true, y_pred, label='', is_regression=True, label2=''):\n",
    "    print('==================', label2)\n",
    "    ### For regression\n",
    "    if is_regression:\n",
    "        print('mean_absolute_error',label,':', sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "        print('mean_squared_error',label,':', sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        print('r2 score',label,':', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "        #     print('max_error',label,':', sklearn.metrics.max_error(y_true, y_pred))\n",
    "        return sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
    "    else:\n",
    "        ### FOR Classification\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('average_precision_score',label,':', sklearn.metrics.average_precision_score(y_true, y_pred))\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('accuracy_score',label,':', sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        print('f1_score',label,':', sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "        matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        print(matrix)\n",
    "        TP,TN,FP,FN = matrix[1][1],matrix[0][0],matrix[0][1],matrix[1][0]\n",
    "        Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = 2*(Recall * Precision) / (Recall + Precision)\n",
    "        print('Acc', Accuracy, 'Prec', Precision, 'Rec', Recall, 'F1',F1)\n",
    "        return sklearn.metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "living-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== \n",
      "mean_absolute_error  : 0.49990338\n",
      "mean_squared_error  : 0.24995096\n",
      "r2 score  : -5.9040197397663974e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24995096"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(inputs)\n",
    "print_evaluation_metrics(np.array(outputs), np.array(preds), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-genealogy",
   "metadata": {},
   "source": [
    "## Predict on test sets and produce binary submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "starting-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "variable-pleasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== SPLIT on 0.1\n",
      "f1_score  : 0.6807387862796834\n",
      "[[  0 484]\n",
      " [  0 516]]\n",
      "Acc 0.516 Prec 0.516 Rec 1.0 F1 0.6807387862796834\n",
      "================== SPLIT on 0.2\n",
      "f1_score  : 0.6807387862796834\n",
      "[[  0 484]\n",
      " [  0 516]]\n",
      "Acc 0.516 Prec 0.516 Rec 1.0 F1 0.6807387862796834\n",
      "================== SPLIT on 0.30000000000000004\n",
      "f1_score  : 0.6807387862796834\n",
      "[[  0 484]\n",
      " [  0 516]]\n",
      "Acc 0.516 Prec 0.516 Rec 1.0 F1 0.6807387862796834\n",
      "================== SPLIT on 0.4\n",
      "f1_score  : 0.6807387862796834\n",
      "[[  0 484]\n",
      " [  0 516]]\n",
      "Acc 0.516 Prec 0.516 Rec 1.0 F1 0.6807387862796834\n",
      "================== SPLIT on 0.5\n",
      "f1_score  : 0.6807387862796834\n",
      "[[  0 484]\n",
      " [  0 516]]\n",
      "Acc 0.516 Prec 0.516 Rec 1.0 F1 0.6807387862796834\n",
      "================== SPLIT on 0.6\n",
      "f1_score  : 0.0\n",
      "[[484   0]\n",
      " [516   0]]\n",
      "Acc 0.484 Prec nan Rec 0.0 F1 nan\n",
      "================== SPLIT on 0.7000000000000001\n",
      "f1_score  : 0.0\n",
      "[[484   0]\n",
      " [516   0]]\n",
      "Acc 0.484 Prec nan Rec 0.0 F1 nan\n",
      "================== SPLIT on 0.8\n",
      "f1_score  : 0.0\n",
      "[[484   0]\n",
      " [516   0]]\n",
      "Acc 0.484 Prec nan Rec 0.0 F1 nan\n",
      "================== SPLIT on 0.9\n",
      "f1_score  : 0.0\n",
      "[[484   0]\n",
      " [516   0]]\n",
      "Acc 0.484 Prec nan Rec 0.0 F1 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
    "    df_sub['pred_bi'] = (test_preds > split)\n",
    "\n",
    "    print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "    df_sub.to_csv('sub3.csv', index=False)\n",
    "    df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "external-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== SPLIT on 0.9\n",
      "f1_score  : 0.6807387862796834\n",
      "[[  0 484]\n",
      " [  0 516]]\n",
      "Acc 0.516 Prec 0.516 Rec 1.0 F1 0.6807387862796834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>pred_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black teen's response to violence in his commu...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor  pred_bi\n",
       "0  What kind of cat should you take into the  des...   True     True\n",
       "1  Remember when people used to have to be in sha...   True     True\n",
       "2  Pizza is always good. - everyone we'll see abo...   True     True\n",
       "3  What's 6 inches long hard, bent, and in my pan...   True     True\n",
       "4  Black teen's response to violence in his commu...  False     True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['pred_bi'] = (test_preds > 0.5)\n",
    "\n",
    "print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "df_sub.to_csv('sub.csv', index=False)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "removable-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts that the model correctly predicts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>pred_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of cat should you take into the  des...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when people used to have to be in sha...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Do infants have as much fun in infancy as adul...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Look on the bright side would be horrible advi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Why are giraffes slow to apologize? it takes t...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I think some drugs should be legalized... but ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>What did miss muffet and saddam hussein have i...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>My 83 year old grandfather is still trying to ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  humor  pred_bi\n",
       "0    What kind of cat should you take into the  des...   True     True\n",
       "1    Remember when people used to have to be in sha...   True     True\n",
       "2    Pizza is always good. - everyone we'll see abo...   True     True\n",
       "3    What's 6 inches long hard, bent, and in my pan...   True     True\n",
       "6    Do infants have as much fun in infancy as adul...   True     True\n",
       "..                                                 ...    ...      ...\n",
       "994  Look on the bright side would be horrible advi...   True     True\n",
       "996  Why are giraffes slow to apologize? it takes t...   True     True\n",
       "997  I think some drugs should be legalized... but ...   True     True\n",
       "998  What did miss muffet and saddam hussein have i...   True     True\n",
       "999  My 83 year old grandfather is still trying to ...   True     True\n",
       "\n",
       "[516 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Texts that the model correctly predicts:')\n",
    "df_sub[df_sub['pred_bi']==df_sub['humor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "located-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts that the model failed to correctly predict:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>pred_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black teen's response to violence in his commu...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'make me a sandwich' is making us hungry, deli...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Funded kickstarters: food products we can't wa...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>China says it wants smooth military ties with ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lance armstrong used rugs: not the headline we...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>These are our relationships as depicted by foo...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Dazzling photos show northern lights shimmerin...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>What an april fools day prank says about the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Beauty cheat sheet: products that make beauty ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Watch: dude with rod in his head seems pretty ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  humor  pred_bi\n",
       "4    Black teen's response to violence in his commu...  False     True\n",
       "5    'make me a sandwich' is making us hungry, deli...  False     True\n",
       "7    Funded kickstarters: food products we can't wa...  False     True\n",
       "10   China says it wants smooth military ties with ...  False     True\n",
       "13   Lance armstrong used rugs: not the headline we...  False     True\n",
       "..                                                 ...    ...      ...\n",
       "987  These are our relationships as depicted by foo...  False     True\n",
       "988  Dazzling photos show northern lights shimmerin...  False     True\n",
       "989  What an april fools day prank says about the ...  False     True\n",
       "991  Beauty cheat sheet: products that make beauty ...  False     True\n",
       "995  Watch: dude with rod in his head seems pretty ...  False     True\n",
       "\n",
       "[484 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Texts that the model failed to correctly predict:')\n",
    "df_sub[df_sub['pred_bi']!=df_sub['humor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-uruguay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
